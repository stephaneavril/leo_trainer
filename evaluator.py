# evaluator.py

import os
import re
import textwrap
import cv2
import numpy as np
from openai import OpenAI
from openai import OpenAIError
from dotenv import load_dotenv
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def evaluate_interaction(user_text, leo_text, video_path=None):
    """
    Eval√∫a la conversaci√≥n y el lenguaje corporal del participante si hay video.
    Retorna evaluaci√≥n p√∫blica (usuario) y evaluaci√≥n RH (t√©cnica).
    """

    def basic_keywords_eval(text):
        score = 0
        keywords = ["beneficio", "estudio", "s√≠ntoma", "tratamiento", "reflujo", "mecanismo", "eficacia", "seguridad"]
        for kw in keywords:
            if kw in text.lower():
                score += 1
        return score

    def detect_closure_language(text):
        closure_patterns = ["compromiso", "siguiente paso", "acordamos", "puedo contar con"]
        return any(p in text.lower() for p in closure_patterns)

    def detect_visual_cues_from_video(path):
        try:
            cap = cv2.VideoCapture(path)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            frontal_frames = 0
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

            for _ in range(min(100, frame_count)):
                ret, frame = cap.read()
                if not ret:
                    break
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                faces = face_cascade.detectMultiScale(gray, 1.3, 5)
                if len(faces) > 0:
                    frontal_frames += 1
            cap.release()
            ratio = frontal_frames / min(100, frame_count)
            if ratio >= 0.7:
                return "‚úÖ Te mostraste visible y profesional frente a c√°mara.", "Correcta"
            else:
                return "‚ö†Ô∏è Aseg√∫rate de mantenerte visible durante toda la sesi√≥n.", "Mejorar visibilidad"
        except Exception as e:
            return f"‚ö†Ô∏è Error en an√°lisis visual: {str(e)}", "Indeterminado"

    score = basic_keywords_eval(user_text)
    closure_ok = detect_closure_language(user_text)
    visual_feedback, visual_eval = detect_visual_cues_from_video(video_path) if video_path else ("‚ö†Ô∏è Sin video disponible.", "No evaluado")

    sales_model_score = {
        "diagnostico": any(kw in user_text.lower() for kw in ["c√≥mo", "qu√©", "cu√°ndo", "desde cu√°ndo", "por qu√©"]),
        "argumentacion": any(kw in user_text.lower() for kw in ["beneficio", "eficaz", "estudio", "seguridad", "mecanismo"]),
        "validacion": any(kw in user_text.lower() for kw in ["entiendo", "veo que", "comprendo", "es l√≥gico"]),
        "cierre": closure_ok
    }
    model_applied_steps = sum(sales_model_score.values())

    active_listening_score = sum(1 for phrase in ["entiendo", "comprendo", "veo que", "lo que dices", "tiene sentido"] if phrase in user_text.lower())

    # GPT feedback
    feedback_level = "alto"
    if score <= 2 and not closure_ok:
        gpt_feedback = (
            "‚ö†Ô∏è Tu desempe√±o mostr√≥ importantes √°reas de mejora. No se observaron elementos clave del modelo de ventas ni argumentos cl√≠nicos s√≥lidos. "
            "Revisa tus argumentos cient√≠ficos y practica c√≥mo responder con evidencia m√©dica."
        )
        feedback_level = "cr√≠tico"
    else:
        try:
            completion = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "Eres un coach experto en entrenamientos cl√≠nicos. S√© claro, motivador y profesional."},
                    {"role": "user", "content": f"""Act√∫a como evaluador de una simulaci√≥n m√©dica.
Participante: {user_text}
M√©dico (Leo): {leo_text}
Eval√∫a al participante de forma motivadora y constructiva."""}
                ],
                temperature=0.4,
            )
            gpt_feedback = completion.choices[0].message.content.strip()
        except OpenAIError as e:
            gpt_feedback = f"‚ö†Ô∏è Evaluaci√≥n GPT-4 no disponible: {str(e)}"
            feedback_level = "error"

    public_summary = textwrap.dedent(f"""
        {gpt_feedback}

        {visual_feedback}

        √Åreas sugeridas:
        - Aseg√∫rate de responder con evidencia m√©dica.
        - Refuerza el uso del modelo de ventas (sin mencionarlo expl√≠citamente).
        - Recuerda manejar bien cada objeci√≥n m√©dica.
        - Mant√©n contacto visual con la c√°mara y buena presencia.
    """)

    internal_summary = textwrap.dedent(f"""
        üìã Evaluaci√≥n t√©cnica (RH):

        üß† Conocimientos t√©cnicos
        - Palabras clave cient√≠ficas: {score}/8

        üéØ Aplicaci√≥n del modelo de ventas
        - Diagn√≥stico: {'‚úÖ' if sales_model_score['diagnostico'] else '‚ùå'}
        - Argumentaci√≥n: {'‚úÖ' if sales_model_score['argumentacion'] else '‚ùå'}
        - Validaci√≥n: {'‚úÖ' if sales_model_score['validacion'] else '‚ùå'}
        - Cierre: {'‚úÖ' if sales_model_score['cierre'] else '‚ùå'}
        ({model_applied_steps}/4 pasos aplicados)

        üéß Escucha activa: {'Alta' if active_listening_score >= 4 else 'Moderada' if active_listening_score >= 2 else 'Baja'} ({active_listening_score}/5)

        üìπ Presencia en video: {visual_eval}
    """)

    return {
        "public": public_summary.strip(),
        "internal": internal_summary.strip(),
        "level": feedback_level
    }
